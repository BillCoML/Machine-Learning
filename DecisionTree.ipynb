{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/tanhoangminhco/Documents/Coding/Python/Machine Learning/datasets/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, threshold=None, key_feature=None, ig=None, left=None, right=None, decision=None):\n",
    "        #only for condition node\n",
    "        self.threshold = threshold\n",
    "        self.key_feature = key_feature\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.ig = ig\n",
    "        \n",
    "        #only for leaf\n",
    "        self.decision = decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, min_samples_split=2 ,max_layers=2):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_layers = max_layers\n",
    "        self.layers = 0\n",
    "        \n",
    "    def fit(self, dataset):\n",
    "        data = dataset.values\n",
    "        self.root = self.build_tree(data ,current_layer=0)#When layer(depth)=0, it means root Node\n",
    "    \n",
    "    def build_tree(self, dataset, current_layer):\n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        if (num_samples >= self.min_samples_split and current_layer<=self.max_layers):\n",
    "            best_split = self.best_split(dataset, num_features)\n",
    "            self.layers = current_layer\n",
    "            if best_split['information_gain']>0:\n",
    "                left_subtree = self.build_tree(best_split[\"leftData\"], current_layer+1)\n",
    "                right_subtree = self.build_tree(best_split[\"rightData\"], current_layer+1)\n",
    "                return Node(best_split['threshold'], best_split['feature_index'], best_split['information_gain'],\n",
    "                            left_subtree, right_subtree)\n",
    "        \n",
    "        decision = self.calculate_leaf_value(Y)\n",
    "        return Node(decision=decision)\n",
    "            \n",
    "    def best_split(self, dataset, num_features):\n",
    "        best_split = {}\n",
    "        maxIG = -float('inf')\n",
    "    \n",
    "        for feature_index in range(num_features):\n",
    "            thresholds = np.unique(dataset[:, feature_index])\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                \n",
    "                dataleft = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "                dataright = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "                if (len(dataleft)>0) and (len(dataright)>0): #Without this [:,-1] is impossible\n",
    "                    information_gain = self.information_gain(dataset[:,-1], dataleft[:,-1], dataright[:,-1])\n",
    "                    if (information_gain > maxIG):\n",
    "                        maxIG = information_gain\n",
    "                        best_split['feature_index'] = feature_index\n",
    "                        best_split['threshold'] = threshold\n",
    "                        best_split['information_gain'] = information_gain\n",
    "                        best_split['leftData'] = dataleft\n",
    "                        best_split['rightData'] = dataright\n",
    "        \n",
    "        return best_split\n",
    "    \n",
    "    def entropy(self, dataset):\n",
    "        entropy = 0\n",
    "        labels = np.unique(dataset)\n",
    "        for label in labels:\n",
    "            ratio = len(dataset[dataset==label])/len(dataset)\n",
    "            entropy += ratio * np.log2(ratio)\n",
    "        return -entropy\n",
    "\n",
    "    def information_gain(self, parent, left, right):\n",
    "        weightL = len(left) / len(parent)\n",
    "        weightR = len(right) / len(parent)\n",
    "        return self.entropy(parent) - weightL*self.entropy(left) - weightR*self.entropy(right)\n",
    "    \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return [self.predictHelper(self.root, x) for x in X]\n",
    "\n",
    "    \n",
    "    def predictHelper(self, cur, x):\n",
    "        if (cur.decision):\n",
    "            return cur.decision\n",
    "        key = x[cur.key_feature]\n",
    "        if key <= cur.threshold:\n",
    "            return self.predictHelper(cur.left, x)\n",
    "        if key > cur.threshold:\n",
    "            return self.predictHelper(cur.right, x)\n",
    "    \n",
    "    def precision(self, tree, actual):\n",
    "        correct = 0\n",
    "        for i in range(len(tree)):\n",
    "            if tree[i] == actual[i]:\n",
    "                correct += 1\n",
    "        return correct/len(tree)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.decision is not None:\n",
    "            print(tree.decision)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.key_feature), \"<=\", tree.threshold, \"?\", tree.ig)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "            \n",
    "def precision(tree, actual):\n",
    "        correct = 0\n",
    "        for i in range(len(tree)):\n",
    "            if tree[i] == actual[i]:\n",
    "                correct += 1\n",
    "        return correct/len(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set , test_set = train_test_split(data, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.9 ? 0.9340680553754911\n",
      " left:Setosa\n",
      " right:X_3 <= 1.7 ? 0.8001056702702978\n",
      "  left:X_3 <= 1.4 ? 0.12136724088771567\n",
      "    left:Versicolor\n",
      "    right:Versicolor\n",
      "  right:Virginica\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree(3)\n",
    "tree.fit(train_set)\n",
    "x = tree.predict(test_set.iloc[:,:-1].values)\n",
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.precision(x, test_set.iloc[:,-1].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
